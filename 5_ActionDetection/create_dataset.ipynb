{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T21:54:59.757797Z",
     "start_time": "2025-09-02T21:54:58.211940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import time\n",
    "from frame_utilities import *"
   ],
   "id": "1e4ab5553a3cfe99",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T21:59:19.157434Z",
     "start_time": "2025-09-02T21:59:19.148534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "videos_path = \"videos\"\n",
    "images_path = \"images\""
   ],
   "id": "bf7b773258a4ce6c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Obtain All Frames From Videos",
   "id": "1327c06fc6518b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for action_dir in os.listdir(videos_path):\n",
    "    frame_count = 0\n",
    "\n",
    "    print(f\"Creating images for action {action_dir}...\")\n",
    "    os.makedirs(os.path.join(images_path, action_dir), exist_ok=True)\n",
    "\n",
    "    for video_name in os.listdir(os.path.join(videos_path, action_dir)):\n",
    "        # Open the video file\n",
    "        video_path = os.path.join(videos_path, action_dir, video_name)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  # End of video\n",
    "\n",
    "            # Save frame as a JPG file\n",
    "            output_path = os.path.join(images_path, action_dir, f\"{action_dir}_frame_{frame_count:05d}.jpg\")\n",
    "            cv2.imwrite(output_path, frame)\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    print(f\"Saved {frame_count} {action_dir} images.\")\n",
    "\n",
    "print(\"Image creation done.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Load Models",
   "id": "14a626f342a9410e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T21:58:26.416839Z",
     "start_time": "2025-09-02T21:58:26.237488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "providers = [\"DmlExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "\n",
    "# Load YOLO model\n",
    "session_coco = onnxruntime.InferenceSession(\"yolo11n.onnx\", providers=providers)\n",
    "input_name_coco = session_coco.get_inputs()[0].name\n",
    "output_name_coco = session_coco.get_outputs()[0].name\n",
    "print(f\"1st ONNX model loaded successfully using providers: {session_coco.get_providers()}.\")\n",
    "\n",
    "# Load volleyball YOLO model\n",
    "session_volleyball = onnxruntime.InferenceSession(\"yolo11n_vb.onnx\", providers=providers)\n",
    "input_name_volleyball = session_volleyball.get_inputs()[0].name\n",
    "output_name_volleyball = session_volleyball.get_outputs()[0].name\n",
    "print(f\"2nd ONNX model loaded successfully using providers: {session_volleyball.get_providers()}.\")\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "print(\"MediaPipe Pose model initialized.\")"
   ],
   "id": "a66b3926dc910f8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st ONNX model loaded successfully using providers: ['CPUExecutionProvider'].\n",
      "2nd ONNX model loaded successfully using providers: ['CPUExecutionProvider'].\n",
      "MediaPipe Pose model initialized.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Create Dataset",
   "id": "d0eef6b40dac76f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T23:35:27.192514Z",
     "start_time": "2025-09-02T23:21:39.163504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lists to store extracted data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "print(\"--- Starting raw_dataset creation loop through images ---\")\n",
    "# Loop through each action directory (e.g., 'serving', 'blocking')\n",
    "for action_dir in os.listdir(images_path):\n",
    "\n",
    "    print(f\"Processing images for action: {action_dir}...\")\n",
    "    # Loop through each image within the current action directory\n",
    "    for img_file_name in os.listdir(os.path.join(images_path, action_dir)):\n",
    "        data_aux = []\n",
    "\n",
    "        img_path_full = os.path.join(images_path, action_dir, img_file_name)\n",
    "        img = cv2.imread(img_path_full)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image '{img_file_name}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        original_frame_shape = img.shape\n",
    "\n",
    "        start_inference_time = time.time() # track inference runtime\n",
    "\n",
    "        # Detect volleyballs\n",
    "        input_ball = preprocess_yolo_input(frame_rgb)\n",
    "        ball_outs = session_volleyball.run([output_name_volleyball], {input_name_volleyball: input_ball})\n",
    "        ball_boxes, ball_scores, _ = postprocess_yolo_output(ball_outs[0], original_frame_shape, conf_threshold=0.5)\n",
    "\n",
    "        if len(ball_boxes) > 0:\n",
    "\n",
    "            # Detect people\n",
    "            input_coco = preprocess_yolo_input(frame_rgb)\n",
    "            coco_outs = session_coco.run([output_name_coco], {input_name_coco: input_coco})\n",
    "            coco_boxes, coco_scores, coco_class_ids = postprocess_yolo_output(coco_outs[0], original_frame_shape, conf_threshold=0.5)\n",
    "\n",
    "            person_boxes = []\n",
    "            person_scores = []\n",
    "\n",
    "            for i, class_id in enumerate(coco_class_ids):\n",
    "                if class_id == 0:  # COCO class 0 = person\n",
    "                    person_boxes.append(coco_boxes[i])\n",
    "                    person_scores.append(coco_scores[i])\n",
    "\n",
    "            if len(person_boxes) > 0:\n",
    "\n",
    "                # Take the most confidently detected ball\n",
    "                ball_box_index = np.argmax(ball_scores)\n",
    "                ball_box = ball_boxes[ball_box_index]\n",
    "                ball_x_min, ball_y_min, ball_x_max, ball_y_max = ball_box\n",
    "\n",
    "                closest_person_box = person_boxes[0]\n",
    "                min_distance = get_distance_person_ball_np(closest_person_box, ball_box)\n",
    "                for person_box in person_boxes:\n",
    "                    distance = get_distance_person_ball_np(person_box, ball_box)\n",
    "                    if distance < min_distance:\n",
    "                        closest_person_box = person_box\n",
    "                        min_distance = distance\n",
    "\n",
    "                person_x_min, person_y_min, person_x_max, person_y_max = closest_person_box\n",
    "\n",
    "                # Clip coordinates to be within frame bounds (important for cropping)\n",
    "                person_x_min = max(0, min(person_x_min, original_frame_shape[1] - 1))\n",
    "                person_y_min = max(0, min(person_y_min, original_frame_shape[0] - 1))\n",
    "                person_x_max = max(0, min(person_x_max, original_frame_shape[1]))\n",
    "                person_y_max = max(0, min(person_y_max, original_frame_shape[0]))\n",
    "\n",
    "                # Ensure valid crop dimensions before proceeding\n",
    "                if person_x_min <= person_x_max and person_y_min <= person_y_max:\n",
    "\n",
    "                    person_frame_roi = frame_rgb[person_y_min:person_y_max, person_x_min:person_x_max]\n",
    "\n",
    "                    # Check if ROI is not empty after clipping\n",
    "                    if person_frame_roi.size > 0:\n",
    "\n",
    "                        square_person_frame, pad_left, pad_top = pad_frame_to_square(person_frame_roi)\n",
    "                        pose_results = pose.process(square_person_frame)\n",
    "\n",
    "                        if pose_results.pose_landmarks:\n",
    "\n",
    "                            # Selecting relevant landmarks and getting absolute coords\n",
    "                            relevant_landmarks = pose_results.pose_landmarks.landmark[11:25]\n",
    "\n",
    "                            # Get min/max coordinates of selected pose landmarks for normalization\n",
    "                            pose_x_coords = [landmark.x for landmark in relevant_landmarks]\n",
    "                            pose_y_coords = [landmark.y for landmark in relevant_landmarks]\n",
    "\n",
    "                            pose_x_min, pose_x_max = min(pose_x_coords), max(pose_x_coords)\n",
    "                            pose_y_min, pose_y_max = min(pose_y_coords), max(pose_y_coords)\n",
    "\n",
    "                            # Calculate ranges for normalization, add small epsilon to avoid division by zero\n",
    "                            x_range = pose_x_max - pose_x_min\n",
    "                            y_range = pose_y_max - pose_y_min\n",
    "                            if x_range == 0: x_range = 1e-6\n",
    "                            if y_range == 0: y_range = 1e-6\n",
    "\n",
    "                            # Normalize pose landmark coordinates and add pose to data_aux\n",
    "                            for landmark in relevant_landmarks:\n",
    "                                pose_x_normalized = (landmark.x - pose_x_min) / x_range\n",
    "                                pose_y_normalized = (landmark.y - pose_y_min) / y_range\n",
    "                                data_aux.append(pose_x_normalized)\n",
    "                                data_aux.append(pose_y_normalized)\n",
    "\n",
    "                            # Make ball coords relative to pose bounding box\n",
    "                            ball_x_min_relative = (ball_x_min - pose_x_min) / x_range\n",
    "                            ball_y_min_relative = (ball_y_min - pose_y_min) / y_range\n",
    "                            ball_size_x = (ball_x_max - ball_x_min) / x_range\n",
    "                            ball_size_y = (ball_y_max - ball_y_min) / y_range\n",
    "                            ball_diameter = max(ball_size_x, ball_size_y)\n",
    "\n",
    "                            # Add ball data to data_aux\n",
    "                            data_aux.append(ball_x_min_relative)\n",
    "                            data_aux.append(ball_y_min_relative)\n",
    "                            data_aux.append(ball_diameter)\n",
    "\n",
    "                            # Ensure data_aux has the correct number of features for your model (2 * 14 + 3 = 31)\n",
    "                            if len(data_aux) == 31:\n",
    "                                data.append(data_aux)\n",
    "                                labels.append(str(action_dir))\n",
    "\n",
    "# Save the collected data and labels to a pickle file\n",
    "with open(\"data.pickle\", 'wb') as f:\n",
    "    pickle.dump({'data': data, 'labels': labels}, f)"
   ],
   "id": "3208f79d8c1f3aff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting raw_dataset creation loop through images ---\n",
      "Processing images for action: ATTACK...\n",
      "Processing images for action: BUMP...\n",
      "Processing images for action: NONE...\n",
      "Processing images for action: SET...\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
